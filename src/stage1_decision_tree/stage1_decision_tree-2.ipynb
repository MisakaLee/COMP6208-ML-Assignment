{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Data...\n",
      "Done\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52482 entries, 0 to 52481\n",
      "Data columns (total 9 columns):\n",
      "time         52482 non-null float64\n",
      "frontal      52482 non-null float64\n",
      "vertical     52482 non-null float64\n",
      "lateral      52482 non-null float64\n",
      "id           52482 non-null int64\n",
      "rssi         52482 non-null float64\n",
      "phase        52482 non-null float64\n",
      "frequency    52482 non-null float64\n",
      "activity     52482 non-null int64\n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"loop through files in S1_Dataset directory\"\"\"\n",
    "\"\"\"create 2D data matrix by appending each new dataset to the bottom of data matrixx\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "S1_PATH = os.path.join('..','..','Datasets_Healthy_Older_People','S1_Dataset')\n",
    "S2_PATH = os.path.join('..','..','Datasets_Healthy_Older_People','S2_Dataset')\n",
    "print('Importing Data...')\n",
    "s1_data = pd.DataFrame()\n",
    "for filename in os.listdir(S1_PATH):\n",
    "    if filename != 'README.txt':\n",
    "        data_path = os.path.join(S1_PATH, filename)\n",
    "        data=pd.read_csv(data_path, header=None)\n",
    "        s1_data = s1_data.append(data, ignore_index=True)\n",
    "s1_data.columns = ['time','frontal','vertical','lateral','id','rssi','phase','frequency','activity']\n",
    "print('Done')\n",
    "s1_data.info()\n",
    "#s1_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"split the data into training and test\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "s1_train_set, s1_test_set = train_test_split(s1_data, test_size = 0.2, random_state = 1)\n",
    "#s1_train_set.info()\n",
    "#s1_train_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for this task (stage 1 decition tree 2), keep the acclerometer and RSSI\"\"\"\n",
    "s1_train_set_s1dt =  s1_train_set.drop(columns=['time','phase','frequency'])\n",
    "s1_train_set_s1dt_features = s1_train_set_s1dt.drop(columns=['activity'])\n",
    "s1_train_set_s1dt_labels = s1_train_set_s1dt.drop(columns=['frontal','vertical','lateral', 'id', 'rssi'])\n",
    "#s1_train_set_s1dt.head()\n",
    "#s1_train_set_s1dt_features.head()\n",
    "#s1_train_set_s1dt_labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"normalize the features\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(s1_train_set_s1dt_features)\n",
    "s1_train_set_s1dt_features = scaler.transform(s1_train_set_s1dt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"train the decision tree model\"\"\"\n",
    "from sklearn import tree\n",
    "dt_clf = tree.DecisionTreeClassifier(criterion='gini',\n",
    "                                     splitter='best',\n",
    "                                     max_depth=100, \n",
    "                                     min_samples_split=2,\n",
    "                                     presort=False)\n",
    "#a complex tree increases recall at the expense of precision\n",
    "dt_clf = dt_clf.fit(s1_train_set_s1dt_features, s1_train_set_s1dt_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98942555, 0.98871025, 0.98956696])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"evaluate the trained model using cross validation score\"\"\"\n",
    "from  sklearn.model_selection import cross_val_score\n",
    "cross_val_score(dt_clf, s1_train_set_s1dt_features, s1_train_set_s1dt_labels, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11920,    26,    11,   154],\n",
       "       [    3,  3462,     1,    35],\n",
       "       [   12,     0, 24791,     6],\n",
       "       [  154,    41,     3,  1366]], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"evaluate the trained model using cross validation predict and the confusion matrix\"\"\"\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "s1_train_set_s1dt_predict = cross_val_predict(dt_clf, s1_train_set_s1dt_features, s1_train_set_s1dt_labels, cv=3)\n",
    "s1dt_conf_mx = confusion_matrix(s1_train_set_s1dt_labels, s1_train_set_s1dt_predict)\n",
    "s1dt_conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sit on bed precision: 0.9860203490776739\n",
      "sit on bed recall: 0.9842292131120469\n",
      "sit on chair precision: 0.9810144516860301\n",
      "sit on chair recall: 0.988860325621251\n",
      "lying precision: 0.9993953075868741\n",
      "lying recall: 0.9992744568503366\n",
      "ambulating precision: 0.8750800768737989\n",
      "ambulating recall: 0.8734015345268542\n"
     ]
    }
   ],
   "source": [
    "\"\"\"evaluate the trained model in terms of precision and recall\"\"\"\n",
    "\"\"\"1: sit on bed, 2: sit on chair, 3: lying, 4: ambulating\"\"\"\n",
    "for index, activity in [(0, \"sit on bed\"), (1, \"sit on chair\"), (2, \"lying\"), (3, \"ambulating\")]:\n",
    "    precision = s1dt_conf_mx[index,index]/sum(s1dt_conf_mx[:,index])\n",
    "    recall = s1dt_conf_mx[index,index]/sum(s1dt_conf_mx[index,:])\n",
    "    print(activity + \" precision: \" + str(precision))\n",
    "    print(activity + \" recall: \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s1dt_rssi.svg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"visualize the decision tree\"\"\"\n",
    "\"\"\"graph exported as an .svg because it is huge\"\"\"\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(dt_clf, out_file=None, \n",
    "                                feature_names=['frontal','vertical','lateral', 'id', 'rssi'], \n",
    "                                class_names=['sit on bed', 'sit on chair', 'lying', 'ambulating'],\n",
    "                                rounded=True, filled=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.format = 'svg'\n",
    "graph.render(\"s1dt_rssi\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
