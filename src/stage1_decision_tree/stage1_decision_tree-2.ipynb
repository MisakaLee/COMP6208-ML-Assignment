{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Data...\n",
      "Done\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52482 entries, 0 to 52481\n",
      "Data columns (total 9 columns):\n",
      "time         52482 non-null float64\n",
      "frontal      52482 non-null float64\n",
      "vertical     52482 non-null float64\n",
      "lateral      52482 non-null float64\n",
      "id           52482 non-null int64\n",
      "rssi         52482 non-null float64\n",
      "phase        52482 non-null float64\n",
      "frequency    52482 non-null float64\n",
      "activity     52482 non-null int64\n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"loop through files in S1_Dataset directory\"\"\"\n",
    "\"\"\"create 2D data matrix by appending each new dataset to the bottom of data matrixx\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "S1_PATH = os.path.join('..','..','Datasets_Healthy_Older_People','S1_Dataset')\n",
    "S2_PATH = os.path.join('..','..','Datasets_Healthy_Older_People','S2_Dataset')\n",
    "print('Importing Data...')\n",
    "s1_data = pd.DataFrame()\n",
    "for filename in os.listdir(S1_PATH):\n",
    "    if filename != 'README.txt':\n",
    "        data_path = os.path.join(S1_PATH, filename)\n",
    "        data=pd.read_csv(data_path, header=None)\n",
    "        s1_data = s1_data.append(data, ignore_index=True)\n",
    "s1_data.columns = ['time','frontal','vertical','lateral','id','rssi','phase','frequency','activity']\n",
    "print('Done')\n",
    "s1_data.info()\n",
    "#s1_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"split the data into training and test\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "s1_train_set, s1_test_set = train_test_split(s1_data, test_size = 0.2, random_state = 1)\n",
    "#s1_train_set.info()\n",
    "#s1_train_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for this task (stage 1 decition tree 2), keep the acclerometer and RSSI\"\"\"\n",
    "s1_train_set_s1dt =  s1_train_set.drop(columns=['time','id','phase','frequency'])\n",
    "s1_train_set_s1dt_features = s1_train_set_s1dt.drop(columns=['activity'])\n",
    "s1_train_set_s1dt_labels = s1_train_set_s1dt.drop(columns=['frontal','vertical','lateral','rssi'])\n",
    "#s1_train_set_s1dt.head()\n",
    "#s1_train_set_s1dt_features.head()\n",
    "#s1_train_set_s1dt_labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"normalize the features\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(s1_train_set_s1dt_features)\n",
    "s1_train_set_s1dt_features = scaler.transform(s1_train_set_s1dt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"train the decision tree model\"\"\"\n",
    "from sklearn import tree\n",
    "dt_clf = tree.DecisionTreeClassifier()\n",
    "dt_clf = dt_clf.fit(s1_train_set_s1dt_features, s1_train_set_s1dt_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11542,   411,    14,   144],\n",
       "       [  467,  2985,     0,    49],\n",
       "       [    6,     2, 24796,     5],\n",
       "       [  172,    59,     3,  1330]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"evaluate the trained model using cross validation and the confusion matrix\"\"\"\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "s1_train_set_s1dt_predict = cross_val_predict(dt_clf, s1_train_set_s1dt_features, s1_train_set_s1dt_labels, cv=3)\n",
    "s1dt_conf_mx = confusion_matrix(s1_train_set_s1dt_labels, s1_train_set_s1dt_predict)\n",
    "s1dt_conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sit on bed precision: 0.9470747517846886\n",
      "sit on bed recall: 0.9530179175955743\n",
      "sit on chair precision: 0.8634654324558866\n",
      "sit on chair recall: 0.8526135389888603\n",
      "lying precision: 0.9993148752669971\n",
      "lying recall: 0.999475996614132\n",
      "ambulating precision: 0.8704188481675392\n",
      "ambulating recall: 0.850383631713555\n"
     ]
    }
   ],
   "source": [
    "\"\"\"evaluate the trained model in terms of precision and recall\"\"\"\n",
    "\"\"\"1: sit on bed, 2: sit on chair, 3: lying, 4: ambulating\"\"\"\n",
    "for index, activity in [(0, \"sit on bed\"), (1, \"sit on chair\"), (2, \"lying\"), (3, \"ambulating\")]:\n",
    "    precision = s1dt_conf_mx[index,index]/sum(s1dt_conf_mx[:,index])\n",
    "    recall = s1dt_conf_mx[index,index]/sum(s1dt_conf_mx[index,:])\n",
    "    print(activity + \" precision: \" + str(precision))\n",
    "    print(activity + \" recall: \" + str(recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
